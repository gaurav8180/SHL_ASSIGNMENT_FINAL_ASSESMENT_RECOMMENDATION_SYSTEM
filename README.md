# SHL Assessment Recommendation System

A comprehensive AI-powered recommendation system that matches job descriptions to relevant SHL assessments using advanced RAG (Retrieval-Augmented Generation) techniques, vector search, and LLM-based reranking.

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.68+-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.0+-red.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

# SHL Assessment Recommendation System


# Live Deployment

**API Endpoint:** https://shl-backend-xvq9.onrender.com/docs#/default/recommend_recommend_post

**Frontend URL:** https://shl-frontend-wv3d.onrender.com/

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Technical Stack](#technical-stack)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Documentation](#api-documentation)
- [Evaluation](#evaluation)
- [Project Structure](#project-structure)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

The SHL Assessment Recommendation System is designed to help organizations quickly identify the most relevant SHL assessments for specific job roles. By analyzing job descriptions using natural language processing and semantic search, the system provides 5-10 targeted assessment recommendations complete with detailed metadata.

### Key Capabilities

- **Intelligent Query Understanding**: Extracts key information from job descriptions including role, skills, preferences, and required test types
- **Hybrid Search**: Combines dense vector search (semantic) and sparse retrieval (BM25) for optimal recall
- **LLM-Powered Reranking**: Uses Google's Gemini 2.5 Flash for context-aware reranking of results
- **Query Expansion**: Automatically enriches queries with synonyms and related terms
- **Adaptive Chunking**: Smart document segmentation for improved retrieval accuracy

## âœ¨ Features

- ğŸ” **Multi-View Document Embedding**: Creates multiple embeddings per assessment (full text, title, description, signals)
- ğŸ§  **LLM-Based Query Analysis**: Extracts structured information from free-form job descriptions
- ğŸ”„ **Reciprocal Rank Fusion (RRF)**: Intelligently merges results from multiple retrieval strategies
- ğŸ“Š **Comprehensive Metadata**: Includes duration, test types, remote testing support, and IRT/adaptive capabilities
- ğŸŒ **Web Interface**: User-friendly Streamlit UI for easy interaction
- ğŸš€ **REST API**: FastAPI backend for programmatic access
- ğŸ“ˆ **Evaluation Framework**: Built-in metrics and testing utilities

## ğŸ—ï¸ Architecture

### System Flow

```
Job Description Input
        â†“
Query Analysis (LLM) â†’ Extract: role, skills, preferences, duration, test_types
        â†“
Query Expansion (LLM) â†’ Add synonyms & related terms
        â†“
Parallel Retrieval:
    â”œâ”€ Dense Search (Qdrant Vector DB + MMR)
    â””â”€ Sparse Search (BM25)
        â†“
Hybrid Fusion (RRF)
        â†“
LLM Reranking (Top 50 â†’ Top 10)
        â†“
Final Recommendations
```

### Technical Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Frontend (Streamlit)                â”‚
â”‚  - Job Description Input                         â”‚
â”‚  - URL Parsing                                   â”‚
â”‚  - Results Display                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Backend (FastAPI)                      â”‚
â”‚  - /recommend endpoint                           â”‚
â”‚  - Request validation                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Recommendation Pipeline (main.py)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. Query Analysis                        â”‚   â”‚
â”‚  â”‚    - Extract structured info (LLM)      â”‚   â”‚
â”‚  â”‚    - Generate expansion terms (LLM)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 2. Hybrid Retrieval                      â”‚   â”‚
â”‚  â”‚    - Dense: Qdrant (MMR, k=40)          â”‚   â”‚
â”‚  â”‚    - Sparse: BM25 (k=80)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 3. Fusion & Reranking                    â”‚   â”‚
â”‚  â”‚    - RRF merge (top 60)                  â”‚   â”‚
â”‚  â”‚    - LLM rerank (top 10)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Qdrant Vector Database                   â”‚   â”‚
â”‚  â”‚  - Multi-view embeddings                 â”‚   â”‚
â”‚  â”‚  - HNSW index (m=64, ef=512)            â”‚   â”‚
â”‚  â”‚  - Cosine similarity                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Google Gemini 2.5 Flash                 â”‚   â”‚
â”‚  â”‚  - Query analysis                        â”‚   â”‚
â”‚  â”‚  - Query expansion                       â”‚   â”‚
â”‚  â”‚  - Result reranking                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technical Stack

### Backend
- **FastAPI**: High-performance async web framework
- **LangChain**: LLM orchestration and RAG pipeline
- **LangGraph**: State machine for complex workflows
- **Google Generative AI**: Gemini 2.5 Flash for LLM operations
- **Qdrant**: Vector database for semantic search
- **Sentence Transformers**: Text embeddings (text-embedding-004)

### Frontend
- **Streamlit**: Interactive web interface
- **BeautifulSoup4**: Web scraping for URL-based job descriptions
- **Pandas**: Data manipulation and presentation

### Data Processing
- **RecursiveCharacterTextSplitter**: Adaptive document chunking
- **BM25**: Sparse retrieval (keyword-based search)
- **MMR (Maximal Marginal Relevance)**: Diversity in dense search results

### DevOps
- **Uvicorn**: ASGI server
- **python-dotenv**: Environment configuration
- **Rich**: Enhanced console output

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- Anaconda/Miniconda (recommended)
- Google API Key (for Gemini)
- Qdrant Cloud account (or local Qdrant instance)

### Step-by-Step Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/shl-recommendation-system.git
cd shl-recommendation-system
```

2. **Create and activate virtual environment**
```bash
# Using venv
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Or using conda
conda create -n shl-recommender python=3.10
conda activate shl-recommender
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env with your credentials
```

Required environment variables:
- `GOOGLE_API_KEY`: Your Google Generative AI API key
- `QDRANT_URL`: Your Qdrant instance URL
- `QDRANT_API_KEY`: Your Qdrant API key

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the root directory:

```env
GOOGLE_API_KEY=your_google_api_key_here
QDRANT_URL=your_qdrant_url.cloud.qdrant.io
QDRANT_API_KEY=your_qdrant_api_key_here
```

### Qdrant Configuration

The system automatically:
- Creates the collection if it doesn't exist
- Configures HNSW indexing (m=64, ef_construct=512)
- Uses cosine similarity for vector comparison
- Validates vector dimensions (768 for text-embedding-004)

### Model Configuration

Default models (configurable in `main.py`):
- **LLM**: `gemini-2.5-flash` (temperature=0)
- **Embeddings**: `models/text-embedding-004`
- **Vector dimension**: 768

## ğŸš€ Usage

### Running the Backend API

```bash
# Development mode
uvicorn app:app --reload --host 0.0.0.0 --port 8000

# Production mode
uvicorn app:app --host 0.0.0.0 --port 8000 --workers 4
```

### Running the Streamlit UI

```bash
streamlit run ui/app.py
```

The UI will be available at `http://localhost:8501`

### Using the API Directly

```python
import requests

response = requests.post(
    "http://localhost:8000/recommend",
    json={
        "job_description": "Looking for a Java developer with Spring Boot experience"
    }
)

recommendations = response.json()["recommendations"]
for rec in recommendations:
    print(f"{rec['name']}: {rec['url']}")
```

### Command Line Testing

```bash
python main.py
```

This runs a test query defined in the `if __name__ == "__main__"` block.

## ğŸ“š API Documentation

### POST /recommend

Recommends SHL assessments based on a job description.

**Request Body:**
```json
{
  "job_description": "string"
}
```

**Response:**
```json
{
  "recommendations": [
    {
      "name": "Java 8 (New)",
      "url": "https://www.shl.com/solutions/products/...",
      "remote_testing_support": "Yes",
      "adaptive_irt_support": "No",
      "duration": "18 minutes",
      "test_types": ["Knowledge"]
    }
  ]
}
```

**Status Codes:**
- `200`: Success
- `400`: Invalid request
- `500`: Server error

### Interactive API Documentation

FastAPI provides automatic API documentation:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## ğŸ“Š Evaluation

### Running Evaluations

```bash
python eval/train_and_evaluate.py
```

This script:
1. Loads labeled training data from `Gen_AI Dataset (1).xlsx`
2. Runs recommendations for each query
3. Calculates Recall@10 metrics
4. Generates detailed evaluation reports
5. Saves results to `evaluation_results.json`

### Metrics

- **Recall@K**: Percentage of relevant assessments found in top K recommendations
- **Mean Recall@10**: Average recall across all test queries
- **Per-Query Analysis**: Individual performance breakdown

### Sample Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      Evaluation Results              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Mean Recall@10    â”‚ 0.4111          â•‘
â•‘ Number of Queries â”‚ 10              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ“ Project Structure

```
shl-recommendation-system/
â”‚
â”œâ”€â”€ main.py                      # Core recommendation pipeline
â”œâ”€â”€ app.py                       # FastAPI application (root)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env                         # Environment variables (not in repo)
â”œâ”€â”€ .env.example                # Template for environment variables
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app.py                  # FastAPI application (alternate)
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py                  # Streamlit web interface
â”‚   â””â”€â”€ requirements.txt        # UI-specific dependencies
â”‚
â”œâ”€â”€ eval/
â”‚   â””â”€â”€ train_and_evaluate.py  # Evaluation framework
â”‚
â”œâ”€â”€ shl_assessments.json        # Assessment catalog (1000+ assessments)
â”œâ”€â”€ Gen_AI Dataset (1).xlsx     # Labeled training data
â”œâ”€â”€ evaluation_results.json     # Evaluation metrics output
â”‚
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml            # Streamlit theme configuration
â”‚
â”œâ”€â”€ .venv/                     # Virtual environment (not in repo)
â”‚
â””â”€â”€ README.md                  # This file
```

## ğŸ”¬ Technical Deep Dive

### Multi-View Document Embedding Strategy

Each SHL assessment is represented by 4 different embedding views:

1. **Full Document**: Complete assessment information
2. **Title Only**: High-signal assessment name
3. **Short Description**: First 300 characters
4. **Signals**: Condensed metadata (test types, duration, flags)

This approach improves recall by matching different aspects of queries to different document representations.

### Adaptive Chunking

Documents are split using two strategies:
- **Short chunks**: 320 chars, 80 overlap (for texts < 800 chars)
- **Long chunks**: 800 chars, 200 overlap (for longer texts)

This ensures optimal chunk size for both brief and detailed content.

### Hybrid Retrieval with RRF

The system combines:
- **Dense retrieval** (Qdrant): Semantic similarity using embeddings
- **Sparse retrieval** (BM25): Keyword matching

Results are merged using Reciprocal Rank Fusion:
```
RRF_score = 1 / (k + rank)
```

where `k=300` is a constant and `rank` is the position in each retriever's results.

### LLM-Based Query Enhancement

**Query Analysis**: Extracts structured information:
```json
{
  "role": "Java Developer",
  "skills": ["Java", "Spring Boot", "SQL"],
  "preferences": ["coding assessments", "adaptive"],
  "duration": "40 minutes",
  "test_types": ["Knowledge", "Coding"]
}
```

**Query Expansion**: Generates 10-20 related terms to improve recall without explicitly mentioning them in the query.

### Performance Optimizations

- **gRPC connection** to Qdrant for faster communication
- **MMR diversity** in dense search to avoid redundant results
- **Cached embeddings** for repeated queries (via Qdrant)
- **Async operations** throughout the pipeline
- **Rate limiting** protection with delays between evaluation queries

